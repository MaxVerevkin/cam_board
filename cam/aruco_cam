#!/usr/bin/env python

import argparse
import configparser
import cv2
import os
import numpy

if(__name__ == "__main__"):

    # parsing command line arguments {

    parser = argparse.ArgumentParser(description = "Filter web cam image to look like a white/black board. Hot keys: q (quit).")
    parser.add_argument("--invert" , "-i" , action = "store_true" , help = "Invert colors.")
    parser.add_argument("--denoise" , "-d" , action = "store_true" , help = "Denoise.")
    parser.add_argument("--fullscreen" , "-f" , action = "store_true" , help = "Full screen.")
    parser.add_argument("--warp" , "-w" , action = "store_true" , help = "Don't warp image to writable area.")
    parser.add_argument("--out" , "-o" , action = "store_true" , help = "QR code outside of writable area.")
    parser.add_argument("--path" , "-p" , help = "Path to directory where frames will be saved. By default this is the current directory.")
    args = parser.parse_args() 

    save_dir = os.getcwd()
    if(args.path != None):
        save_dir = args.path

    # } parsing command line arguments


    # script directory {

    script_path = os.path.dirname(os.path.realpath(__file__))

    # } script directory

    # reading configuration file {

    config = configparser.ConfigParser()
    config.read(os.path.join(script_path , "aruco_cam_config"))
   
    blockSize = int(config["adaptiveThreshold"]["blockSize"])
    C = int(config["adaptiveThreshold"]["C"])
    buff = int(config["perspectiveMatrix"]["buffer"])

    # } reading configuration file

    # getting camera {
    cap = cv2.VideoCapture(0)
    # } getting camera 

    # qr detector {
    qrCodeDetector = cv2.QRCodeDetector()
    # } qr detector

    # window for cv {
    cv2.namedWindow('frame' , cv2.WINDOW_NORMAL)
    if(args.fullscreen):
        cv2.setWindowProperty('frame' , cv2.WND_PROP_FULLSCREEN , cv2.WINDOW_FULLSCREEN)
    # } window for cv

    # main loop {

    try:
    
        # points surrounfing the QR code available
        got_points = False
        # points surrounfing the QR code
        pointsglob = None
        # image number
        image_number = 0

        m_list = []

        aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_250)
        parameters =  cv2.aruco.DetectorParameters_create()

        while(True):
            # Capture frame-by-frame
            ret, frame = cap.read()

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=parameters)
            
            if(len(corners) == 4):
                allids = [0 , 1 , 2 , 3]
                pts = [None , None , None , None]
                for i in range(4):
                    pts[ids[i][0]] = [
                            (int(corners[i][0][0][0]) , int(corners[i][0][0][1])) ,
                            (int(corners[i][0][1][0]) , int(corners[i][0][1][1])) ,
                            (int(corners[i][0][2][0]) , int(corners[i][0][2][1])) ,
                            (int(corners[i][0][3][0]) , int(corners[i][0][3][1]))
                            ];

                ok = not None in pts
            
                if(ok):
                    got_points = True
                    pointsglob = pts

            warped = frame

            if(got_points and (not args.warp)):

                #warped = cv2.line(frame , pointsglob[0][0] , pointsglob[1][1] , (0 , 0 , 255))
                #warped = cv2.line(frame , pointsglob[1][1] , pointsglob[3][2] , (0 , 0 , 255))
                #warped = cv2.line(frame , pointsglob[3][2] , pointsglob[2][3] , (0 , 0 , 255))
                #warped = cv2.line(frame , pointsglob[2][0] , pointsglob[0][3] , (0 , 0 , 255))
                
                src = numpy.array([pointsglob[0][0] , pointsglob[1][1] , pointsglob[3][2] , pointsglob[2][3]] , numpy.float32)
                dst = numpy.array([[frame.shape[1] , frame.shape[0]] , [0.0 , frame.shape[0]] , [0.0 , 0.0] , [frame.shape[1] , 0.0]] , numpy.float32)
                m = cv2.getPerspectiveTransform(src , dst)
                m_list.append(m)
                if(len(m_list) > buff):
                    m_list.pop(0)
                m_avg = numpy.zeros(m.shape , dtype = m.dtype)
                for mm in m_list:
                    m_avg = m_avg + mm

                m_avg = m_avg / float(len(m_list))
                warped = cv2.warpPerspective(frame , m_avg , (frame.shape[1] , frame.shape[0]))


            # Our operations on the frame come here
            if(args.denoise):
                #war1 = cv2.cvtColor(warped , cv2.COLOR_BGR2GRAY)
                (b, g, r) = cv2.split(warped)
                war1_b = cv2.adaptiveThreshold(b,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,blockSize,C)
                war1_g = cv2.adaptiveThreshold(g,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,blockSize,C)
                war1_r = cv2.adaptiveThreshold(r,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,blockSize,C)
                #war1 = cv2.merge((war1 , war1 , war1))
                #war1 = cv2.Laplacian(warped, ksize=3, ddepth=cv2.CV_16S)
                #war1 = cv2.Canny(warped, threshold1=40, threshold2=100)
                #war1 = cv2.bitwise_not(war1)
                ret , warped_b = cv2.threshold(b , 0 , 255 , cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                ret , warped_g = cv2.threshold(g , 0 , 255 , cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                ret , warped_r = cv2.threshold(r , 0 , 255 , cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                frac = 0.6
                #mean_b = numpy.maximum(frac * war1 , warped_b).astype(numpy.uint8)
                #mean_g = numpy.maximum(frac * war1 , warped_g).astype(numpy.uint8)
                #mean_r = numpy.maximum(frac * war1 , warped_r).astype(numpy.uint8)
                mean_b = (frac * war1_b + (1.0 - frac) * warped_b).astype(numpy.uint8)
                mean_g = (frac * war1_g + (1.0 - frac) * warped_g).astype(numpy.uint8)
                mean_r = (frac * war1_r + (1.0 - frac) * warped_r).astype(numpy.uint8)
                #warped = cv2.merge((0.0 * war1 + 1.0 * warped_b , 0.0 * war1 + 1.0 * warped_g , 0.0 * war1 + 1.0 * warped_r))
                warped = cv2.merge((mean_b , mean_g , mean_r))
                #print(mean_b.dtype)
                #mean = (0.2 * war1 + 0.8 * war2).astype(int)
                #warped = mean

            tosave = warped

            if(args.invert):
                warped = cv2.bitwise_not(warped)

            # Display the resulting frame
            cv2.imshow('frame',warped)

            key = cv2.waitKey(1)
 
            if(key == ord('q')):
                break
            elif(key == ord('s')):
                #got_points = False
                #pointsglob = None
                cv2.imwrite(os.path.join(save_dir , str(image_number).zfill(4) + ".png") , tosave)
                image_number += 1




        # } main loop

    finally:

        cap.release()
        cv2.destroyAllWindows()

